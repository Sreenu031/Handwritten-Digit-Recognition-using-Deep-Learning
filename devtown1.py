# -*- coding: utf-8 -*-
"""devtown1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1394SnnGYargC5feBwBkWvmMfQLtdGsVO
"""

import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

(X_train,y_train),(X_test,y_test)=tf.keras.datasets.mnist.load_data()

print("X_train ",X_train.shape)

X_test[0]

fig , axs =plt.subplots(3,3)
count=0
for i in range(3):
  for j in range(3):
    axs[i,j].imshow(X_train[count])
    count+=1

X_train=tf.keras.utils.normalize(X_train,axis=1)
X_test=tf.keras.utils.normalize(X_test,axis=1)

model=tf.keras.models.Sequential()

model.add(tf.keras.layers.Flatten(input_shape=(28,28)))

model.add(tf.keras.layers.Dense(units=128,activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(units=128,activation=tf.nn.relu))

model.add(tf.keras.layers.Dense(units=10,activation=tf.nn.softmax))

model.summary()

model.compile(loss="sparse_categorical_crossentropy",optimizer="Adam")

history=model.fit(X_train,y_train,epochs=10,validation_split=0.2)

y_prob=model.predict(X_test)

y_pred=y_prob.argmax(axis=1)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

plt.imshow(X_test[10])

model.predict(X_test[10].reshape(1,28,28)).argmax(axis=1)